(window.webpackJsonp=window.webpackJsonp||[]).push([[26],{380:function(_,v,t){"use strict";t.r(v);var e=t(45),d=Object(e.a)({},(function(){var _=this,v=_.$createElement,t=_._self._c||v;return t("ContentSlotsDistributor",{attrs:{"slot-key":_.$parent.slotKey}},[t("h1",{attrs:{id:"决策树之随机森林"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#决策树之随机森林"}},[_._v("#")]),_._v(" 决策树之随机森林")]),_._v(" "),t("p",[t("RouterLink",{attrs:{to:"/AI/cart1.html"}},[_._v("在 CART 分类回归树")]),_._v("的基础之上，我们可以很容易的掌握随机森林算法，它们之间的区别在于，CART 决策树较容易过拟合，而随机森林可以在一定程度上解决该问题。")],1),_._v(" "),t("p",[_._v("随机森林的主要思想是：使用随机性产生出一系列简单的决策树，并组合它们的预测结果为最终的结果，可谓三个臭皮匠赛过一个诸葛亮，下面我们就来具体了解一下。")]),_._v(" "),t("h2",{attrs:{id:"产生随机森林的具体步骤"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#产生随机森林的具体步骤"}},[_._v("#")]),_._v(" 产生随机森林的具体步骤")]),_._v(" "),t("p",[_._v("产生随机森林的步骤大致为三步")]),_._v(" "),t("ol",[t("li",[_._v("准备样本")]),_._v(" "),t("li",[_._v("产生决策树")]),_._v(" "),t("li",[_._v("循环第 1 、2 步，直到产生足够的决策树，一般为上百个")])]),_._v(" "),t("p",[_._v("在第 1 步，它是一个可放回抽样，即所产生的样本是允许重复的，这种抽样又被称为 Bootstrap，例如我们有以下 dummy 数据")]),_._v(" "),t("table",[t("thead",[t("tr",[t("th",[_._v("胸口疼痛")]),_._v(" "),t("th",[_._v("血液循环正常")]),_._v(" "),t("th",[_._v("血管堵塞")]),_._v(" "),t("th",[_._v("体重")]),_._v(" "),t("th",[_._v("患心脏病")])])]),_._v(" "),t("tbody",[t("tr",[t("td",[_._v("No")]),_._v(" "),t("td",[_._v("No")]),_._v(" "),t("td",[_._v("No")]),_._v(" "),t("td",[_._v("125")]),_._v(" "),t("td",[_._v("No")])]),_._v(" "),t("tr",[t("td",[_._v("Yes")]),_._v(" "),t("td",[_._v("Yes")]),_._v(" "),t("td",[_._v("Yes")]),_._v(" "),t("td",[_._v("180")]),_._v(" "),t("td",[_._v("Yes")])]),_._v(" "),t("tr",[t("td",[_._v("Yes")]),_._v(" "),t("td",[_._v("Yes")]),_._v(" "),t("td",[_._v("No")]),_._v(" "),t("td",[_._v("210")]),_._v(" "),t("td",[_._v("No")])]),_._v(" "),t("tr",[t("td",[_._v("Yes")]),_._v(" "),t("td",[_._v("No")]),_._v(" "),t("td",[_._v("Yes")]),_._v(" "),t("td",[_._v("167")]),_._v(" "),t("td",[_._v("Yes")])])])]),_._v(" "),t("p",[_._v("在做完 Bootstrap 之后，可能的样本数据如下")]),_._v(" "),t("table",[t("thead",[t("tr",[t("th",[_._v("胸口疼痛")]),_._v(" "),t("th",[_._v("血液循环正常")]),_._v(" "),t("th",[_._v("血管堵塞")]),_._v(" "),t("th",[_._v("体重")]),_._v(" "),t("th",[_._v("患心脏病")])])]),_._v(" "),t("tbody",[t("tr",[t("td",[_._v("Yes")]),_._v(" "),t("td",[_._v("Yes")]),_._v(" "),t("td",[_._v("Yes")]),_._v(" "),t("td",[_._v("180")]),_._v(" "),t("td",[_._v("Yes")])]),_._v(" "),t("tr",[t("td",[_._v("No")]),_._v(" "),t("td",[_._v("No")]),_._v(" "),t("td",[_._v("No")]),_._v(" "),t("td",[_._v("125")]),_._v(" "),t("td",[_._v("No")])]),_._v(" "),t("tr",[t("td",[_._v("Yes")]),_._v(" "),t("td",[_._v("No")]),_._v(" "),t("td",[_._v("Yes")]),_._v(" "),t("td",[_._v("167")]),_._v(" "),t("td",[_._v("Yes")])]),_._v(" "),t("tr",[t("td",[_._v("Yes")]),_._v(" "),t("td",[_._v("No")]),_._v(" "),t("td",[_._v("Yes")]),_._v(" "),t("td",[_._v("167")]),_._v(" "),t("td",[_._v("Yes")])])])]),_._v(" "),t("p",[_._v("可见，样本数据中，第 3 条和第 4 条样本是一样的，都对应的是原始数据中的第 4 条。")]),_._v(" "),t("p",[_._v("接下来，就是要使用上面的样本数据来产生决策树了，产生决策树的方法和 CART 基本一致，唯一的不同地方在于，节点的构建不是来自于全部的候选特征，而是先从中随机的选择 n 个特征，在这 n 个特征中找出一个作为最佳节点。")]),_._v(" "),t("p",[_._v("举个例子，假设 n = 2，且我们随机选择了「血液循环正常」和「血管堵塞」这两个特征来产生根节点，如下：")]),_._v(" "),t("table",[t("thead",[t("tr",[t("th",[_._v("血液循环正常")]),_._v(" "),t("th",[_._v("血管堵塞")]),_._v(" "),t("th",[_._v("患心脏病")])])]),_._v(" "),t("tbody",[t("tr",[t("td",[_._v("Yes")]),_._v(" "),t("td",[_._v("Yes")]),_._v(" "),t("td",[_._v("Yes")])]),_._v(" "),t("tr",[t("td",[_._v("No")]),_._v(" "),t("td",[_._v("No")]),_._v(" "),t("td",[_._v("No")])]),_._v(" "),t("tr",[t("td",[_._v("No")]),_._v(" "),t("td",[_._v("Yes")]),_._v(" "),t("td",[_._v("Yes")])]),_._v(" "),t("tr",[t("td",[_._v("No")]),_._v(" "),t("td",[_._v("Yes")]),_._v(" "),t("td",[_._v("Yes")])])])]),_._v(" "),t("p",[_._v("我们将在上述两个特征中选择一个合适的特征作为根节点，假设在计算完 Gini 不纯度之后，「血液循环正常」这个特征胜出，那么我们的根节点便是「血液循环正常」，如下图所示")]),_._v(" "),t("p",[t("img",{attrs:{src:"https://github.com/jieniu/articles/blob/master/docs/.vuepress/public/rf_root.png?raw=true",alt:"rf_root"}})]),_._v(" "),t("p",[_._v("接下来我们还需要构建根节点下面的节点，下一个节点将会在剩下的「胸口疼痛」、「血管堵塞」和「体重」三个特征中产生，但我们依然不会计算所有这 3 个特征的 Gini 不纯度，而是从中随机选择 2 个特征，取这 2 个特征中的 Gini 不纯度较低者作为节点。")]),_._v(" "),t("p",[_._v("例如我们随机选到了「胸口疼痛」和「体重」这两列，如下：")]),_._v(" "),t("table",[t("thead",[t("tr",[t("th",[_._v("胸口疼痛")]),_._v(" "),t("th",[_._v("体重")]),_._v(" "),t("th",[_._v("患心脏病")])])]),_._v(" "),t("tbody",[t("tr",[t("td",[_._v("Yes")]),_._v(" "),t("td",[_._v("180")]),_._v(" "),t("td",[_._v("Yes")])]),_._v(" "),t("tr",[t("td",[_._v("No")]),_._v(" "),t("td",[_._v("125")]),_._v(" "),t("td",[_._v("No")])]),_._v(" "),t("tr",[t("td",[_._v("Yes")]),_._v(" "),t("td",[_._v("167")]),_._v(" "),t("td",[_._v("Yes")])]),_._v(" "),t("tr",[t("td",[_._v("Yes")]),_._v(" "),t("td",[_._v("167")]),_._v(" "),t("td",[_._v("Yes")])])])]),_._v(" "),t("p",[_._v("假设此时「体重」的 Gini 不纯度更低，那么第 2 个节点便是「体重」，如下图：")]),_._v(" "),t("p",[t("img",{attrs:{src:"https://github.com/jieniu/articles/blob/master/docs/.vuepress/public/rf_node.png?raw=true",alt:"rf_node"}})]),_._v(" "),t("p",[_._v("继续下去，我们便产生了一棵决策树。")]),_._v(" "),t("p",[_._v("随机森林是多棵决策树，在产生完一棵决策树后，接着会循环执行上述过程：Bootstrap 出训练样本，训练决策树，直到树的数量达到设置值——通常为几百棵树。")]),_._v(" "),t("h2",{attrs:{id:"随机森林的预测"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#随机森林的预测"}},[_._v("#")]),_._v(" 随机森林的预测")]),_._v(" "),t("p",[_._v("现在我们产生了几百棵树的随机森林，当我们要预测一条数据时，该怎么做呢？我们会聚合这些树的结果，选择预测结果最多的那个分类作为最终的预测结果。")]),_._v(" "),t("p",[_._v("例如我们现在有一条数据：")]),_._v(" "),t("table",[t("thead",[t("tr",[t("th",[_._v("胸口疼痛")]),_._v(" "),t("th",[_._v("血液循环正常")]),_._v(" "),t("th",[_._v("血管堵塞")]),_._v(" "),t("th",[_._v("体重")]),_._v(" "),t("th",[_._v("患心脏病")])])]),_._v(" "),t("tbody",[t("tr",[t("td",[_._v("Yes")]),_._v(" "),t("td",[_._v("No")]),_._v(" "),t("td",[_._v("No")]),_._v(" "),t("td",[_._v("168")]),_._v(" "),t("td")])])]),_._v(" "),t("p",[_._v("该条数据被所有树预测的结果如下：")]),_._v(" "),t("table",[t("thead",[t("tr",[t("th",[_._v("第几颗树")]),_._v(" "),t("th",[_._v("预测结果")])])]),_._v(" "),t("tbody",[t("tr",[t("td",[_._v("1")]),_._v(" "),t("td",[_._v("Yes")])]),_._v(" "),t("tr",[t("td",[_._v("2")]),_._v(" "),t("td",[_._v("Yes")])]),_._v(" "),t("tr",[t("td",[_._v("...")]),_._v(" "),t("td",[_._v("...")])]),_._v(" "),t("tr",[t("td",[_._v("100")]),_._v(" "),t("td",[_._v("No")])])])]),_._v(" "),t("p",[_._v("上述结果聚合后为：")]),_._v(" "),t("table",[t("thead",[t("tr",[t("th",[_._v("预测结果")]),_._v(" "),t("th",[_._v("次数")])])]),_._v(" "),t("tbody",[t("tr",[t("td",[_._v("Yes")]),_._v(" "),t("td",[_._v("82")])]),_._v(" "),t("tr",[t("td",[_._v("No")]),_._v(" "),t("td",[_._v("18")])])])]),_._v(" "),t("p",[_._v("取最多的那项为最终的预测结果，即 Yes——该病人被诊断为患有心脏病。")]),_._v(" "),t("p",[_._v("以上，随机森林的两个过程："),t("strong",[_._v("B")]),_._v("ootstrap 和 "),t("strong",[_._v("Agg")]),_._v("regate 又被称为 "),t("strong",[_._v("Bagging")]),_._v("。")]),_._v(" "),t("h2",{attrs:{id:"总结"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#总结"}},[_._v("#")]),_._v(" 总结")]),_._v(" "),t("p",[_._v("本文我们一起学习了随机森林的算法，和 CART 决策树比起来，它主要被用来解决过拟合问题，其主要的思想为 Bagging，即随机性有助于增强模型的泛化（Variance） 能力。")]),_._v(" "),t("p",[_._v("参考：")]),_._v(" "),t("ul",[t("li",[t("a",{attrs:{href:"https://www.youtube.com/watch?v=6EXPYzbfLCE&list=PLblh5JKOoLUICTaGLRoHQDuF_7q2GfuJF&index=39",target:"_blank",rel:"noopener noreferrer"}},[_._v("Random Forests"),t("OutboundLink")],1)])]),_._v(" "),t("p",[_._v("相关文章：")]),_._v(" "),t("ul",[t("li",[t("p",[t("RouterLink",{attrs:{to:"/AI/cart1.html"}},[_._v("决策树算法之分类回归树 CART（Classification and Regression Trees）【1】")])],1)]),_._v(" "),t("li",[t("p",[t("RouterLink",{attrs:{to:"/AI/cart2.html"}},[_._v("决策树算法之分类回归树 CART（Classification and Regression Trees）【2】")])],1)])])])}),[],!1,null,null,null);v.default=d.exports}}]);