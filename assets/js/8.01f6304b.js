(window.webpackJsonp=window.webpackJsonp||[]).push([[8],{362:function(t,n,a){"use strict";a.r(n);var i=a(45),r=Object(i.a)({},(function(){var t=this,n=t.$createElement,a=t._self._c||n;return a("ContentSlotsDistributor",{attrs:{"slot-key":t.$parent.slotKey}},[a("h1",{attrs:{id:"machine-learning"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#machine-learning"}},[t._v("#")]),t._v(" Machine Learning")]),t._v(" "),a("h2",{attrs:{id:"machine-learning-2"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#machine-learning-2"}},[t._v("#")]),t._v(" Machine Learning")]),t._v(" "),a("ul",[a("li",[a("p",[a("RouterLink",{attrs:{to:"/AI/ready_for_machine_learning.html"}},[t._v("Machine Leanring 环境准备——搭建 Jupyter Notebook")])],1)]),t._v(" "),a("li",[a("p",[a("RouterLink",{attrs:{to:"/AI/cross-validation.html"}},[t._v("理解「交叉验证」(Cross Validation)")])],1)]),t._v(" "),a("li",[a("p",[a("RouterLink",{attrs:{to:"/AI/confusion-matrix.html"}},[t._v("二分类评估，从混淆矩阵说起")])],1)]),t._v(" "),a("li",[a("p",[a("RouterLink",{attrs:{to:"/AI/bias-variance.html"}},[t._v("理解 Bias 和 Variance")])],1)]),t._v(" "),a("li",[a("p",[a("RouterLink",{attrs:{to:"/AI/cart1.html"}},[t._v("决策树算法之分类回归树 CART（Classification and Regression Trees）【1】")])],1)]),t._v(" "),a("li",[a("p",[a("RouterLink",{attrs:{to:"/AI/cart2.html"}},[t._v("决策树算法之分类回归树 CART（Classification and Regression Trees）【2】")])],1)]),t._v(" "),a("li",[a("p",[a("RouterLink",{attrs:{to:"/AI/rforest.html"}},[t._v("决策树之随机森林")])],1)]),t._v(" "),a("li",[a("p",[a("RouterLink",{attrs:{to:"/AI/adaboost.html"}},[t._v("决策树算法之 AdaBoost")])],1)]),t._v(" "),a("li",[a("p",[a("RouterLink",{attrs:{to:"/AI/lr.html"}},[t._v("深入理解逻辑回归算法")])],1)]),t._v(" "),a("li",[a("p",[a("RouterLink",{attrs:{to:"/AI/gbdt.html"}},[t._v("决策树之 GBDT 算法 - 回归部分")])],1)]),t._v(" "),a("li",[a("p",[a("RouterLink",{attrs:{to:"/AI/gbdt2.html"}},[t._v("决策树之 GBDT 算法 - 分类部分")])],1)]),t._v(" "),a("li",[a("p",[a("RouterLink",{attrs:{to:"/AI/linear-scratch.html"}},[t._v("使用 TensorFlow2.0 实现线性回归")])],1)]),t._v(" "),a("li",[a("p",[a("RouterLink",{attrs:{to:"/AI/softmax.html"}},[t._v("用 TensorFlow2.0 实现 Softmax 多分类")])],1)]),t._v(" "),a("li",[a("p",[a("RouterLink",{attrs:{to:"/AI/dnn.html"}},[t._v("一文读懂神经网络")])],1)]),t._v(" "),a("li",[a("p",[a("RouterLink",{attrs:{to:"/AI/word2vec.html"}},[t._v("一文读懂 Word2vec")])],1)]),t._v(" "),a("li",[a("p",[a("RouterLink",{attrs:{to:"/AI/bert-fine-tune.html"}},[t._v("【译】BERT Fine-Tuning 指南（with PyTorch）")])],1)]),t._v(" "),a("li",[a("p",[a("RouterLink",{attrs:{to:"/AI/understand_ranking_loss.html"}},[t._v("【译】理解 Ranking Loss，Contrastive Loss，Margin Loss，Triplet Loss，Hinge Loss 等易混淆的概念")])],1)])]),t._v(" "),a("h2",{attrs:{id:"《hands-on-machine-learning》学习笔记"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#《hands-on-machine-learning》学习笔记"}},[t._v("#")]),t._v(" 《Hands-On Machine Learning》学习笔记")]),t._v(" "),a("ul",[a("li",[a("p",[a("RouterLink",{attrs:{to:"/AI/homl-ch2.html"}},[t._v("【学习笔记】Hands On Machine Learning - Chap2. End-to-End Machine Learning Project")])],1)]),t._v(" "),a("li",[a("p",[a("RouterLink",{attrs:{to:"/AI/homl-ch3.html"}},[t._v("【学习笔记】Hands On Machine Learning - Chap3. Classification")])],1)])])])}),[],!1,null,null,null);n.default=r.exports}}]);